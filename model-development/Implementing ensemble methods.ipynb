{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "BAGGING (Random Forest Example)\n",
        "load_iris() – loads a small flower dataset used for testing ML models.\n",
        "\n",
        "train_test_split() – splits data into training (80%) and testing (20%).\n",
        "\n",
        "RandomForestClassifier() – creates a bagging model made of many decision trees.\n",
        "\n",
        "fit() – teaches the model using the training data.\n",
        "\n",
        "predict() – uses the learned model to guess labels for new data.\n",
        "\n",
        "accuracy_score() – checks how good those predictions are."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Gradient Boosting model\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = gb.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "print(\"Boosting (Gradient Boosting) Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Boosting (Gradient Boosting) Accuracy: 1.0\n"
        }
      ],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1764836072726
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BOOSTING (Gradient Boosting Example)\n",
        "GradientBoostingClassifier() – builds trees one after another.\n",
        "\n",
        "Each new tree tries to fix the mistakes of the previous ones.\n",
        "\n",
        "fit() trains the boosting model step by step.\n",
        "\n",
        "predict() gets final predictions after all corrections.\n",
        "\n",
        "accuracy_score() evaluates performance.\n",
        "\n",
        "Boosting = train models sequentially → each fixes errors of the last."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Gradient Boosting model\n",
        "gb = GradientBoostingClassifier(random_state=42)\n",
        "gb.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = gb.predict(X_test)\n",
        "\n",
        "# Evaluate accuracy\n",
        "print(\"Boosting (Gradient Boosting) Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Boosting (Gradient Boosting) Accuracy: 1.0\n"
        }
      ],
      "execution_count": 2,
      "metadata": {
        "gather": {
          "logged": 1764836189553
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "STACKING (Combine Models + Meta-Learner)\n",
        "DecisionTreeClassifier() – first base model.\n",
        "\n",
        "SVC() – second base model (SVM).\n",
        "\n",
        "These models each learn differently.\n",
        "\n",
        "LogisticRegression() – the “meta-learner” that learns from their predictions.\n",
        "\n",
        "StackingClassifier() – combines all models into one powerful ensemble.\n",
        "\n",
        "fit() trains the whole stack.\n",
        "\n",
        "predict() uses combined knowledge from all models.\n",
        "\n",
        "accuracy_score() checks performance.\n",
        "\n",
        "Stacking = train multiple models → feed their predictions into a final model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split into train/test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Base models\n",
        "base_estimators = [\n",
        "    ('tree', DecisionTreeClassifier()),\n",
        "    ('svc', SVC(probability=True))\n",
        "]\n",
        "\n",
        "# Meta-learner\n",
        "meta_learner = LogisticRegression()\n",
        "\n",
        "# Build stacking model\n",
        "stack_model = StackingClassifier(\n",
        "    estimators=base_estimators,\n",
        "    final_estimator=meta_learner\n",
        ")\n",
        "\n",
        "# Train stacking model\n",
        "stack_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = stack_model.predict(X_test)\n",
        "print(\"Stacking Accuracy:\", accuracy_score(y_test, y_pred))\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Stacking Accuracy: 1.0\n"
        }
      ],
      "execution_count": 3,
      "metadata": {
        "gather": {
          "logged": 1764836533410
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The perfect accuracy results (1.00) observed for stacking and bagging are due to the limited dataset size and controlled lab conditions. Real-world datasets, which are larger and more complex, typically yield more realistic accuracy scores. These lab results should be interpreted with these constraints in mind."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python310-sdkv2",
      "language": "python",
      "display_name": "Python 3.10 - SDK v2"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}